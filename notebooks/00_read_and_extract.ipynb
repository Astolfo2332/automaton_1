{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First of all we need to start testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download only the mails pdf or atachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eml_info(eml_path):\n",
    "    # Open and parse the .eml file\n",
    "    with open(eml_path, 'rb') as eml_file:\n",
    "        msg = BytesParser(policy=policy.default).parse(eml_file)\n",
    "    \n",
    "    # Extract headers\n",
    "    subject = msg.get('subject', '')\n",
    "    from_ = msg.get('from', '')\n",
    "    to = msg.get('to', '')\n",
    "    date = msg.get('date', '')\n",
    "    \n",
    "    # Extract body (text and HTML)\n",
    "    text_body = \"\"\n",
    "    html_body = \"\"\n",
    "    \n",
    "    if msg.is_multipart():\n",
    "        for part in msg.iter_parts():\n",
    "            content_type = part.get_content_type()\n",
    "            content_disposition = part.get('Content-Disposition')\n",
    "            \n",
    "            if content_type == 'text/plain' and not content_disposition:\n",
    "                text_body = part.get_payload(decode=True).decode(part.get_content_charset())\n",
    "            elif content_type == 'text/html' and not content_disposition:\n",
    "                html_body = part.get_payload(decode=True).decode(part.get_content_charset())\n",
    "            elif part.get_filename():  # Extract attachments\n",
    "                filename = part.get_filename()\n",
    "                with open(filename, 'wb') as f:\n",
    "                    f.write(part.get_payload(decode=True))\n",
    "    else:\n",
    "        if msg.get_content_type() == 'text/plain':\n",
    "            text_body = msg.get_payload(decode=True).decode(msg.get_content_charset())\n",
    "        elif msg.get_content_type() == 'text/html':\n",
    "            html_body = msg.get_payload(decode=True).decode(msg.get_content_charset())\n",
    "    return [html_body]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/\")\n",
    "mails_path = data_path / \"mails\"\n",
    "zips_data = data_path / \"zips\"\n",
    "mail_files = [mails_path / f for f in os.listdir(mails_path)]\n",
    "zip_files = [zips_data / f for f in os.listdir(zips_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails_data = [extract_eml_info(i) for i in mail_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(zip_file_path, extract_to_folder):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(extract_to_folder, exist_ok=True)\n",
    "    \n",
    "    # Open the ZIP file\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        # Extract all the contents into the specified folder\n",
    "        zip_ref.extractall(extract_to_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in zip_files:\n",
    "    extract_zip(i, data_path / \"pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = data_path / \"pdfs\"\n",
    "pdf_files = [pdf_path / f for f in os.listdir(pdf_path) if f.endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/pdfs/fv09012646580082400000791.pdf'),\n",
       " PosixPath('../data/pdfs/fv0800242106021234008100243777.pdf'),\n",
       " PosixPath('../data/pdfs/ad08909411030122300010468.pdf'),\n",
       " PosixPath('../data/pdfs/fv090126465800824000007da.pdf'),\n",
       " PosixPath('../data/pdfs/fv090099897600824c0bf.pdf'),\n",
       " PosixPath('../data/pdfs/ad08909411030122300010673.pdf'),\n",
       " PosixPath('../data/pdfs/ad089094179401224000028AF.pdf'),\n",
       " PosixPath('../data/pdfs/ad089094179401224000028DF.pdf'),\n",
       " PosixPath('../data/pdfs/fv0900411441008230000dcb2.pdf'),\n",
       " PosixPath('../data/pdfs/ad0890941794012230001A094.pdf'),\n",
       " PosixPath('../data/pdfs/ad09011139020002400097930.pdf'),\n",
       " PosixPath('../data/pdfs/fv090126465800823000022a6.pdf'),\n",
       " PosixPath('../data/pdfs/ad0890941794012230001A138.pdf'),\n",
       " PosixPath('../data/pdfs/ad0860029002016240001e00b.pdf'),\n",
       " PosixPath('../data/pdfs/ad080022707101624000195cc.pdf'),\n",
       " PosixPath('../data/pdfs/ad0900378955016240000a5ef.pdf'),\n",
       " PosixPath('../data/pdfs/ad09011139020002400097958.pdf'),\n",
       " PosixPath('../data/pdfs/ad08600290020162400020865.pdf'),\n",
       " PosixPath('../data/pdfs/ad09011139020002400098494.pdf'),\n",
       " PosixPath('../data/pdfs/ad0900795173016240000a360.pdf'),\n",
       " PosixPath('../data/pdfs/ad0860029002016240001f363.pdf'),\n",
       " PosixPath('../data/pdfs/ad09003789550162400009ec1.pdf'),\n",
       " PosixPath('../data/pdfs/ad08909417940122400004D8A.pdf')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(pdf_files[0])\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 02:41:36.872094: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "#from langchain_core.runnables import RunnablePassthrough\n",
    "#from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "#from langchain_core.output_parsers import StrOutputParser\n",
    "#from langchain_community.chat_models import ChatOllama\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = \"mistral\"\n",
    "#model = ChatOllama(model=\"mistral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiki/anaconda3/envs/tensorflow/lib/python3.11/site-packages/transformers/modeling_utils.py:4674: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at TheBloke/Mistral-7B-Instruct-v0.2-GPTQ were not used when initializing MistralForCausalLM: ['model.layers.0.mlp.down_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.v_proj.bias']\n",
      "- This IS expected if you are initializing MistralForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MistralForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "token = os.getenv(\"HG_TOKEN\")\n",
    "model_name = \"TheBloke/Mistral-7B-Instruct-v0.2-GPTQ\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             device_map=\"auto\", # automatically figures out how to best use CPU + GPU for loading model\n",
    "                                             trust_remote_code=False, # prevents running custom model files on your machine\n",
    "                                             revision=\"gptq-8bit-32g-actorder_True\") # which version of mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_prompt = PromptTemplate(\n",
    "    input_variables=[\"documento\"],\n",
    "    template=\"\"\"Eres un asistente de facturas, solo hablas español, vas a recibir\n",
    "    información de varias facturas y debes extraer la siguiente información y presentarla\n",
    "    de esta forma \\n\n",
    "    \n",
    "    Empresa: Nombre de la empresa del documento\n",
    "    Nit: Nit de la empresa del documento\n",
    "    Valor a pagar: Valor a pagar mostrado en el documento\n",
    "    Numero de factura: Numero de factura encontrado en el documento\n",
    "    Valor a pagar: Valor a pagar\n",
    "    IVA: Valor de iva\n",
    "\n",
    "    A partir del siguiente documento:\n",
    "    {documento}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ( {\"documento\": RunnablePassthrough()} | context_prompt | model | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FACTURA ELECTRÓNICA DE VENTA\\n\\nSODIMAC COLOMBIA S.A. NIT 800.242.106-2 Iva Régimen Común ICA Actividad Económica CIIU 4719 Grandes Contribuyentes Resolución 12220 26 DIC 2022 AUTORRETENEDORES Resolución DIAN 00931 de 29 ENE 2009 Agente de Retención de IVA\\n\\nN° 4008100243777\\n\\nINFORMACIÓN DEL CLIENTE\\n\\nRazón Social:\\n\\nNIT\\n\\nDirección\\n\\n: Armando Lopez Florian : 71.624.785 : CL 24 79 A 140\\n\\nFecha de Expedición Fecha de Vencimiento\\n\\nFecha de Validación\\n\\n: 2023/12/19 09:44:02\\n\\n: 2023/12/19\\n\\n: 2023/12/19\\n\\nTeléfono\\n\\n: 3136328200\\n\\nFecha de Compra\\n\\n: 2023/12/19\\n\\nCorreo\\n\\n: arlofl@gmail.com\\n\\nRemisión de Entrega\\n\\nDirección de Entrega\\n\\n:\\n\\nCiudad de Entrega\\n\\n: BOGOTÁ, D.C.\\n\\nForma de Pago\\n\\n: Contado\\n\\nNro O/C\\n\\nPlazo\\n\\n: 0 Dias de Pago\\n\\nTipo Moneda\\n\\n: COP\\n\\nNro. Interno\\n\\n: 33890618\\n\\nMedio de Pago\\n\\n. TARJ CRE/DEB\\n\\nCUFE\\n\\n: 4c2a88ad96c5c3f1fbaf3bf03385d9aa2f2c791a2ffc432e6825d0b9e2a895560bd91e478e1abeb215dc9de2768cf764\\n\\nObservaciones\\n\\n: /\\n\\n1\\n\\nCANT.\\n\\n2\\n\\nSKU\\n\\nDESCRIPCIÓN\\n\\n88132 CAJA CARTON B largo3\\n\\nVR. VENTA UNITARIO\\n\\n6.470,59\\n\\nVR. BRUTO SIN IVA\\n\\n12.941,18\\n\\n% DESCUENTO 0,00\\n\\nVR. DESCUENTO 0,00\\n\\nSUB.TOTAL\\n\\n12.941,18\\n\\n% IVA\\n\\n19,00\\n\\nVR. IVA\\n\\n2.458,82\\n\\nSUB. TOTAL CON IMPTO. 15.400,00\\n\\n2\\n\\n1\\n\\n88128 CAJA CARTON H largo5\\n\\n21.764,71\\n\\n21.764,71\\n\\n0,00\\n\\n0,00\\n\\n21.764,71\\n\\n19,00\\n\\n4.135,29\\n\\n25.900,00\\n\\nVALOR BRUTO DESCUENTO SUB.TOTAL IVA SUB. TOTAL CON IMPTO.\\n\\n$ $ $ $ $\\n\\n34.705,89 0,00 34.705,89 6.594,11 41.300,00\\n\\nSON: CUARENTA Y UN MIL TRESCIENTOS PESOS MCTE\\n\\nTOTAL A PAGAR $\\n\\n41.300,00\\n\\nOBSERVACIONES: /\\n\\n(cid:128)(cid:66)(cid:94)(cid:94)(cid:94)(cid:66)(cid:128)(cid:1)(cid:58)(cid:37)(cid:30)(cid:113)(cid:88)(cid:73)(cid:58)(cid:79)(cid:80)(cid:119)(cid:100)(cid:51)(cid:56)(cid:29)(cid:58)(cid:17)(cid:32)(cid:85)(cid:14)(cid:69)(cid:24)(cid:21)(cid:94)(cid:123)(cid:90)(cid:31)(cid:108)(cid:13)(cid:106)(cid:15)(cid:4)(cid:125)(cid:62)(cid:123)(cid:78)(cid:93)(cid:28)(cid:89)(cid:88)(cid:29)(cid:14)(cid:101)(cid:24)(cid:1)(cid:92)(cid:3)(cid:96)(cid:49)(cid:38)(cid:119)(cid:126)(cid:81)(cid:32)(cid:105)(cid:64)(cid:7)(cid:102)(cid:119)(cid:40)(cid:5)(cid:62)(cid:1)(cid:128)(cid:66)(cid:94)(cid:94)(cid:94)(cid:66)(cid:128)\\n\\n(cid:48)(cid:4)(cid:13)(cid:6)(cid:26)(cid:17)(cid:43)(cid:16)(cid:122)(cid:59)(cid:4)(cid:45)(cid:38)(cid:36)(cid:51)(cid:35)(cid:112)(cid:75)(cid:118)(cid:46)(cid:36)(cid:102)(cid:28)(cid:92)(cid:103)(cid:35)(cid:39)(cid:58)(cid:98)(cid:82)(cid:84)(cid:88)(cid:87)(cid:122)(cid:99)(cid:33)(cid:64)(cid:103)(cid:27)(cid:10)(cid:71)(cid:128)(cid:20)(cid:41)(cid:47)(cid:99)(cid:106)(cid:51)(cid:61)(cid:46)(cid:117)(cid:127)(cid:51)(cid:45)(cid:53)(cid:88)(cid:126)(cid:35)(cid:70)(cid:63)(cid:38)(cid:13)(cid:18)(cid:120)(cid:71)(cid:43)(cid:85)(cid:33)(cid:86)(cid:49)(cid:56)(cid:14)(cid:21)(cid:41)(cid:49)(cid:41)(cid:6)\\n\\n(cid:54)(cid:22)(cid:37)(cid:39)(cid:97)(cid:120)(cid:86)(cid:76)(cid:17)(cid:1)(cid:91)(cid:66)(cid:20)(cid:102)(cid:108)(cid:19)(cid:1)(cid:8)(cid:12)(cid:100)(cid:73)(cid:28)(cid:93)(cid:121)(cid:125)(cid:22)(cid:16)(cid:5)(cid:126)(cid:46)(cid:6)(cid:83)(cid:15)(cid:78)(cid:114)(cid:107)(cid:30)(cid:84)(cid:100)(cid:9)(cid:79)(cid:32)(cid:57)(cid:30)(cid:71)(cid:21)(cid:16)(cid:13)(cid:101)(cid:17)(cid:112)(cid:124)(cid:111)(cid:84)(cid:5)(cid:99)(cid:71)(cid:6)(cid:114)(cid:47)(cid:85)(cid:83)(cid:105)(cid:76)(cid:9)(cid:82)(cid:38)(cid:116)(cid:91)(cid:113)(cid:24)(cid:79)(cid:60)(cid:86)(cid:114)(cid:26)(cid:5)\\n\\nAutorizacion de Numeracion de Facturacion DIAN 18764046140356 del 17/03/2023, Prefijo 4008, Rango 100215905 hasta 150200000 con una vigencia desde el 17/03/2023 hasta 14/09/2024.\\n\\n(cid:128)(cid:23)(cid:20)(cid:125)(cid:112)(cid:25)(cid:43)(cid:57)(cid:16)(cid:96)(cid:63)(cid:81)(cid:87)(cid:5)(cid:115)(cid:61)(cid:85)(cid:32)(cid:120)(cid:123)(cid:122)(cid:120)(cid:28)(cid:103)(cid:64)(cid:89)(cid:43)(cid:89)(cid:32)(cid:67)(cid:86)(cid:30)(cid:9)(cid:34)(cid:124)(cid:7)(cid:111)(cid:114)(cid:116)(cid:2)(cid:77)(cid:68)(cid:94)(cid:35)(cid:89)(cid:5)(cid:16)(cid:73)(cid:75)(cid:41)(cid:112)(cid:126)(cid:64)(cid:43)(cid:5)(cid:26)(cid:45)(cid:2)(cid:44)(cid:42)(cid:33)(cid:41)(cid:45)(cid:128)(cid:97)(cid:43)(cid:15)(cid:34)(cid:96)(cid:73)(cid:11)(cid:89)(cid:32)(cid:89)(cid:10)(cid:110)(cid:13)\\n\\n(cid:30)(cid:96)(cid:34)(cid:60)(cid:103)(cid:84)(cid:86)(cid:118)(cid:124)(cid:24)(cid:76)(cid:48)(cid:74)(cid:1)(cid:51)(cid:9)(cid:9)(cid:101)(cid:106)(cid:5)(cid:56)(cid:93)(cid:32)(cid:19)(cid:114)(cid:84)(cid:107)(cid:87)(cid:98)(cid:75)(cid:47)(cid:54)(cid:57)(cid:128)(cid:72)(cid:91)(cid:96)(cid:118)(cid:8)(cid:94)(cid:44)(cid:70)(cid:112)(cid:118)(cid:28)(cid:107)(cid:113)(cid:101)(cid:83)(cid:93)(cid:75)(cid:86)(cid:39)(cid:70)(cid:79)(cid:10)(cid:16)(cid:70)(cid:25)(cid:27)(cid:119)(cid:10)(cid:58)(cid:94)(cid:36)(cid:5)(cid:119)(cid:30)(cid:68)(cid:113)(cid:87)(cid:69)(cid:86)(cid:125)(cid:87)(cid:119)(cid:53)\\n\\n(cid:68)(cid:71)(cid:112)(cid:13)(cid:6)(cid:125)(cid:43)(cid:43)(cid:40)(cid:102)(cid:85)(cid:55)(cid:3)(cid:73)(cid:69)(cid:120)(cid:94)(cid:124)(cid:67)(cid:26)(cid:79)(cid:85)(cid:98)(cid:38)(cid:79)(cid:4)(cid:53)(cid:7)(cid:31)(cid:9)(cid:123)(cid:123)(cid:106)(cid:81)(cid:45)(cid:102)(cid:44)(cid:83)(cid:45)(cid:32)(cid:101)(cid:117)(cid:128)(cid:117)(cid:98)(cid:10)(cid:117)(cid:89)(cid:83)(cid:88)(cid:23)(cid:127)(cid:109)(cid:9)(cid:91)(cid:97)(cid:15)(cid:35)(cid:98)(cid:109)(cid:74)(cid:41)(cid:115)(cid:119)(cid:83)(cid:41)(cid:84)(cid:57)(cid:15)(cid:8)(cid:8)(cid:99)(cid:43)(cid:53)(cid:15)(cid:126)(cid:54)\\n\\n(cid:92)(cid:1)(cid:62)(cid:127)(cid:64)(cid:21)(cid:86)(cid:13)(cid:32)(cid:72)(cid:4)(cid:111)(cid:43)(cid:44)(cid:78)(cid:122)(cid:122)(cid:61)(cid:88)(cid:91)(cid:79)(cid:47)(cid:6)(cid:29)(cid:24)(cid:37)(cid:6)(cid:125)(cid:56)(cid:2)(cid:49)(cid:60)(cid:36)(cid:45)(cid:14)(cid:87)(cid:30)(cid:46)(cid:78)(cid:80)(cid:108)(cid:6)(cid:59)(cid:24)(cid:102)(cid:101)(cid:104)(cid:13)(cid:118)(cid:109)(cid:80)(cid:120)(cid:64)(cid:72)(cid:94)(cid:100)(cid:22)(cid:52)(cid:33)(cid:98)(cid:51)(cid:38)(cid:38)(cid:126)(cid:92)(cid:53)(cid:104)(cid:19)(cid:8)(cid:37)(cid:30)(cid:101)(cid:88)(cid:28)(cid:85)(cid:66)(cid:68)\\n\\nLa presente Factura Electrónica de Venta, es un título valor de acuerdo con lo establecido en el Código de Comercio y en especial en los artículos 621,772 y 774, el Decreto 2242 del 24 de noviembre de 2015 y el Decreto Único 1074 de mayo de 2015. El presente título valor se asimila en todos sus efectos a una letra de cambio Art.779 del Código de Comercio.\\n\\n(cid:115)(cid:2)(cid:90)(cid:56)(cid:119)(cid:40)(cid:43)(cid:38)(cid:102)(cid:118)(cid:112)(cid:76)(cid:116)(cid:47)(cid:65)(cid:35)(cid:62)(cid:15)(cid:29)(cid:79)(cid:121)(cid:104)(cid:88)(cid:83)(cid:126)(cid:37)(cid:60)(cid:54)(cid:100)(cid:20)(cid:27)(cid:51)(cid:99)(cid:31)(cid:18)(cid:48)(cid:47)(cid:82)(cid:18)(cid:5)(cid:68)(cid:94)(cid:101)(cid:85)(cid:8)(cid:60)(cid:127)(cid:50)(cid:48)(cid:41)(cid:108)(cid:58)(cid:63)(cid:41)(cid:30)(cid:84)(cid:88)(cid:9)(cid:78)(cid:24)(cid:111)(cid:9)(cid:54)(cid:59)(cid:47)(cid:33)(cid:39)(cid:32)(cid:105)(cid:61)(cid:56)(cid:58)(cid:120)(cid:12)(cid:89)(cid:30)(cid:87)\\n\\n(cid:65)(cid:62)(cid:125)(cid:117)(cid:74)(cid:65)(cid:86)(cid:97)(cid:60)(cid:62)(cid:12)(cid:75)(cid:28)(cid:71)(cid:8)(cid:80)(cid:15)(cid:62)(cid:21)(cid:53)(cid:13)(cid:78)(cid:29)(cid:57)(cid:46)(cid:121)(cid:21)(cid:5)(cid:85)(cid:48)(cid:54)(cid:108)(cid:48)(cid:121)(cid:62)(cid:29)(cid:85)(cid:95)(cid:54)(cid:42)(cid:23)(cid:36)(cid:107)(cid:100)(cid:64)(cid:91)(cid:67)(cid:61)(cid:16)(cid:97)(cid:15)(cid:86)(cid:73)(cid:18)(cid:118)(cid:31)(cid:90)(cid:73)(cid:74)(cid:13)(cid:49)(cid:86)(cid:107)(cid:94)(cid:13)(cid:86)(cid:51)(cid:15)(cid:7)(cid:72)(cid:8)(cid:40)(cid:51)(cid:51)(cid:116)(cid:32)(cid:7)\\n\\n(cid:113)(cid:11)(cid:35)(cid:67)(cid:111)(cid:89)(cid:43)(cid:41)(cid:2)(cid:44)(cid:106)(cid:76)(cid:60)(cid:103)(cid:71)(cid:108)(cid:109)(cid:12)(cid:107)(cid:45)(cid:66)(cid:71)(cid:104)(cid:98)(cid:4)(cid:99)(cid:39)(cid:19)(cid:68)(cid:100)(cid:16)(cid:35)(cid:118)(cid:106)(cid:66)(cid:40)(cid:44)(cid:118)(cid:8)(cid:96)(cid:70)(cid:28)(cid:88)(cid:123)(cid:13)(cid:43)(cid:16)(cid:71)(cid:83)(cid:3)(cid:24)(cid:112)(cid:50)(cid:1)(cid:17)(cid:89)(cid:110)(cid:39)(cid:17)(cid:29)(cid:17)(cid:125)(cid:35)(cid:112)(cid:63)(cid:35)(cid:32)(cid:60)(cid:40)(cid:63)(cid:95)(cid:103)(cid:92)(cid:108)(cid:108)(cid:40)(cid:57)\\n\\n(cid:128)(cid:66)(cid:94)(cid:94)(cid:94)(cid:66)(cid:128)(cid:1)(cid:2)(cid:14)(cid:36)(cid:10)(cid:126)(cid:33)(cid:44)(cid:80)(cid:127)(cid:22)(cid:11)(cid:93)(cid:33)(cid:103)(cid:123)(cid:103)(cid:115)(cid:28)(cid:81)(cid:31)(cid:128)(cid:69)(cid:22)(cid:67)(cid:57)(cid:101)(cid:85)(cid:71)(cid:98)(cid:101)(cid:72)(cid:121)(cid:121)(cid:59)(cid:7)(cid:74)(cid:49)(cid:66)(cid:120)(cid:22)(cid:86)(cid:25)(cid:118)(cid:76)(cid:57)(cid:69)(cid:46)(cid:51)(cid:47)(cid:48)(cid:39)(cid:115)(cid:8)(cid:82)(cid:39)(cid:60)(cid:89)(cid:70)(cid:76)(cid:82)(cid:121)(cid:32)(cid:88)(cid:23)(cid:120)(cid:100)(cid:3)(cid:101)(cid:3)\\n\\n1/1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not StringPromptValue",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/langchain_core/runnables/base.py:2878\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2876\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2877\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2878\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2879\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/langchain_core/runnables/base.py:4474\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4460\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[1;32m   4461\u001b[0m \n\u001b[1;32m   4462\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4471\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[1;32m   4472\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4475\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4476\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4477\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4478\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4479\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4483\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4484\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/langchain_core/runnables/base.py:1785\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1782\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1783\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1784\u001b[0m         Output,\n\u001b[0;32m-> 1785\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1793\u001b[0m     )\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1795\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/langchain_core/runnables/config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/langchain_core/runnables/base.py:4330\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4328\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   4329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4330\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4331\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   4332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4333\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[1;32m   4334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/langchain_core/runnables/config.py:398\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    397\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:1033\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1026\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m   1030\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1031\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1032\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m-> 1033\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1034\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1035\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1036\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1037\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1038\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1039\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m   1040\u001b[0m )\n\u001b[1;32m   1042\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1043\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/transformers/models/mistral/modeling_mistral.py:761\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    759\u001b[0m return_legacy_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(past_key_values, Cache) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m--> 761\u001b[0m     past_key_values \u001b[38;5;241m=\u001b[39m DynamicCache\u001b[38;5;241m.\u001b[39mfrom_legacy_cache(past_key_values)\n\u001b[1;32m    762\u001b[0m     return_legacy_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    763\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m    764\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    765\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    766\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/accelerate/hooks.py:169\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.12/site-packages/torch/nn/functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not StringPromptValue"
     ]
    }
   ],
   "source": [
    "chain.invoke(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"Eres un asistente de facturas, solo hablas español, vas a recibir\n",
    "información de varias facturas y debes extraer la siguiente información y presentarla\n",
    "de esta forma y solo con estos datos:\n",
    "\n",
    "Empresa: Nombre de la empresa del documento\n",
    "Nit: Nit de la empresa del documento\n",
    "Valor a pagar: Valor a pagar mostrado en el documento\n",
    "Numero de factura: Numero de factura encontrado en el documento\n",
    "Valor a pagar: Valor a pagar\n",
    "IVA: Valor de iva, este valor es el valor a pagar / 1.19\n",
    "CUFE: CUFE del documento\n",
    "\n",
    "A partir del siguiente documento:\n",
    "\n",
    "\"\"\"\n",
    "#messages = lambda x :[\n",
    "#    {\"role\": \"system\", \"content\": f\"{template}\"},\n",
    "#    {\"role\": \"user\", \"content\": f\"{x}\"},\n",
    "#]\n",
    "\n",
    "def func_messages(text:str, template:str):\n",
    "    WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
    "    messages = lambda x: f\"[INST] {template}{x}[/INST] \\n\"\n",
    "    return messages(WHITESPACE_HANDLER(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pipeline(\"text-generation\", model=model, max_new_tokens=1000, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = func_messages(data[0].page_content, template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "945"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<s>[INST] Eres un asistente de facturas, solo hablas español, vas a recibir\\n    información de varias facturas y debes extraer la siguiente información y presentarla\\n    de esta forma y solo con estos datos:\\n\\n    Empresa: Nombre de la empresa del documento\\n    Nit: Nit de la empresa del documento\\n    Valor a pagar: Valor a pagar mostrado en el documento\\n    Numero de factura: Numero de factura encontrado en el documento\\n    Valor a pagar: Valor a pagar\\n    IVA: Valor de iva\\n    CUFE: CUFE del documento\\n\\n    A partir del siguiente documento:\\n\\n     FACTURA ELECTRÓNICA DE VENTA\\n\\nSODIMAC COLOMBIA S.A. NIT 800.242.106-2 Iva Régimen Común ICA Actividad Económica CIIU 4719 Grandes Contribuyentes Resolución 12220 26 DIC 2022 AUTORRETENEDORES Resolución DIAN 00931 de 29 ENE 2009 Agente de Retención de IVA\\n\\nN° 4008100243777\\n\\nINFORMACIÓN DEL CLIENTE\\n\\nRazón Social:\\n\\nNIT\\n\\nDirección\\n\\n: Armando Lopez Florian : 71.624.785 : CL 24 79 A 140\\n\\nFecha de Expedición Fecha de Vencimiento\\n\\nFecha de Validación\\n\\n: 2023/12/19 09:44:02\\n\\n: 2023/12/19\\n\\n: 2023/12/19\\n\\nTeléfono\\n\\n: 3136328200\\n\\nFecha de Compra\\n\\n: 2023/12/19\\n\\nCorreo\\n\\n: arlofl@gmail.com\\n\\nRemisión de Entrega\\n\\nDirección de Entrega\\n\\n:\\n\\nCiudad de Entrega\\n\\n: BOGOTÁ, D.C.\\n\\nForma de Pago\\n\\n: Contado\\n\\nNro O/C\\n\\nPlazo\\n\\n: 0 Dias de Pago\\n\\nTipo Moneda\\n\\n: COP\\n\\nNro. Interno\\n\\n: 33890618\\n\\nMedio de Pago\\n\\n. TARJ CRE/DEB\\n\\nCUFE\\n\\n: 4c2a88ad96c5c3f1fbaf3bf03385d9aa2f2c791a2ffc432e6825d0b9e2a895560bd91e478e1abeb215dc9de2768cf764\\n\\nObservaciones\\n\\n: /\\n\\n1\\n\\nCANT.\\n\\n2\\n\\nSKU\\n\\nDESCRIPCIÓN\\n\\n88132 CAJA CARTON B largo3\\n\\nVR. VENTA UNITARIO\\n\\n6.470,59\\n\\nVR. BRUTO SIN IVA\\n\\n12.941,18\\n\\n% DESCUENTO 0,00\\n\\nVR. DESCUENTO 0,00\\n\\nSUB.TOTAL\\n\\n12.941,18\\n\\n% IVA\\n\\n19,00\\n\\nVR. IVA\\n\\n2.458,82\\n\\nSUB. TOTAL CON IMPTO. 15.400,00\\n\\n2\\n\\n1\\n\\n88128 CAJA CARTON H largo5\\n\\n21.764,71\\n\\n21.764,71\\n\\n0,00\\n\\n0,00\\n\\n21.764,71\\n\\n19,00\\n\\n4.135,29\\n\\n25.900,00\\n\\nVALOR BRUTO DESCUENTO SUB.TOTAL IVA SUB. TOTAL CON IMPTO.\\n\\n$ $ $ $ $\\n\\n34.705,89 0,00 34.705,89 6.594,11 41.300,00\\n\\nSON: CUARENTA Y UN MIL TRESCIENTOS PESOS MCTE\\n\\nTOTAL A PAGAR $\\n\\n41.300,00\\n\\nOBSERVACIONES: /\\n\\n(cid:128)(cid:66)(cid:94)(cid:94)(cid:94)(cid:66)(cid:128)(cid:1)(cid:58)(cid:37)(cid:30)(cid:113)(cid:88)(cid:73)(cid:58)(cid:79)(cid:80)(cid:119)(cid:100)(cid:51)(cid:56)(cid:29)(cid:58)(cid:17)(cid:32)(cid:85)(cid:14)(cid:69)(cid:24)(cid:21)(cid:94)(cid:123)(cid:90)(cid:31)(cid:108)(cid:13)(cid:106)(cid:15)(cid:4)(cid:125)(cid:62)(cid:123)(cid:78)(cid:93)(cid:28)(cid:89)(cid:88)(cid:29)(cid:14)(cid:101)(cid:24)(cid:1)(cid:92)(cid:3)(cid:96)(cid:49)(cid:38)(cid:119)(cid:126)(cid:81)(cid:32)(cid:105)(cid:64)(cid:7)(cid:102)(cid:119)(cid:40)(cid:5)(cid:62)(cid:1)(cid:128)(cid:66)(cid:94)(cid:94)(cid:94)(cid:66)(cid:128)\\n\\n(cid:48)(cid:4)(cid:13)(cid:6)(cid:26)(cid:17)(cid:43)(cid:16)(cid:122)(cid:59)(cid:4)(cid:45)(cid:38)(cid:36)(cid:51)(cid:35)(cid:112)(cid:75)(cid:118)(cid:46)(cid:36)(cid:102)(cid:28)(cid:92)(cid:103)(cid:35)(cid:39)(cid:58)(cid:98)(cid:82)(cid:84)(cid:88)(cid:87)(cid:122)(cid:99)(cid:33)(cid:64)(cid:103)(cid:27)(cid:10)(cid:71)(cid:128)(cid:20)(cid:41)(cid:47)(cid:99)(cid:106)(cid:51)(cid:61)(cid:46)(cid:117)(cid:127)(cid:51)(cid:45)(cid:53)(cid:88)(cid:126)(cid:35)(cid:70)(cid:63)(cid:38)(cid:13)(cid:18)(cid:120)(cid:71)(cid:43)(cid:85)(cid:33)(cid:86)(cid:49)(cid:56)(cid:14)(cid:21)(cid:41)(cid:49)(cid:41)(cid:6)\\n\\n(cid:54)(cid:22)(cid:37)(cid:39)(cid:97)(cid:120)(cid:86)(cid:76)(cid:17)(cid:1)(cid:91)(cid:66)(cid:20)(cid:102)(cid:108)(cid:19)(cid:1)(cid:8)(cid:12)(cid:100)(cid:73)(cid:28)(cid:93)(cid:121)(cid:125)(cid:22)(cid:16)(cid:5)(cid:126)(cid:46)(cid:6)(cid:83)(cid:15)(cid:78)(cid:114)(cid:107)(cid:30)(cid:84)(cid:100)(cid:9)(cid:79)(cid:32)(cid:57)(cid:30)(cid:71)(cid:21)(cid:16)(cid:13)(cid:101)(cid:17)(cid:112)(cid:124)(cid:111)(cid:84)(cid:5)(cid:99)(cid:71)(cid:6)(cid:114)(cid:47)(cid:85)(cid:83)(cid:105)(cid:76)(cid:9)(cid:82)(cid:38)(cid:116)(cid:91)(cid:113)(cid:24)(cid:79)(cid:60)(cid:86)(cid:114)(cid:26)(cid:5)\\n\\nAutorizacion de Numeracion de Facturacion DIAN 18764046140356 del 17/03/2023, Prefijo 4008, Rango 100215905 hasta 150200000 con una vigencia desde el 17/03/2023 hasta 14/09/2024.\\n\\n(cid:128)(cid:23)(cid:20)(cid:125)(cid:112)(cid:25)(cid:43)(cid:57)(cid:16)(cid:96)(cid:63)(cid:81)(cid:87)(cid:5)(cid:115)(cid:61)(cid:85)(cid:32)(cid:120)(cid:123)(cid:122)(cid:120)(cid:28)(cid:103)(cid:64)(cid:89)(cid:43)(cid:89)(cid:32)(cid:67)(cid:86)(cid:30)(cid:9)(cid:34)(cid:124)(cid:7)(cid:111)(cid:114)(cid:116)(cid:2)(cid:77)(cid:68)(cid:94)(cid:35)(cid:89)(cid:5)(cid:16)(cid:73)(cid:75)(cid:41)(cid:112)(cid:126)(cid:64)(cid:43)(cid:5)(cid:26)(cid:45)(cid:2)(cid:44)(cid:42)(cid:33)(cid:41)(cid:45)(cid:128)(cid:97)(cid:43)(cid:15)(cid:34)(cid:96)(cid:73)(cid:11)(cid:89)(cid:32)(cid:89)(cid:10)(cid:110)(cid:13)\\n\\n(cid:30)(cid:96)(cid:34)(cid:60)(cid:103)(cid:84)(cid:86)(cid:118)(cid:124)(cid:24)(cid:76)(cid:48)(cid:74)(cid:1)(cid:51)(cid:9)(cid:9)(cid:101)(cid:106)(cid:5)(cid:56)(cid:93)(cid:32)(cid:19)(cid:114)(cid:84)(cid:107)(cid:87)(cid:98)(cid:75)(cid:47)(cid:54)(cid:57)(cid:128)(cid:72)(cid:91)(cid:96)(cid:118)(cid:8)(cid:94)(cid:44)(cid:70)(cid:112)(cid:118)(cid:28)(cid:107)(cid:113)(cid:101)(cid:83)(cid:93)(cid:75)(cid:86)(cid:39)(cid:70)(cid:79)(cid:10)(cid:16)(cid:70)(cid:25)(cid:27)(cid:119)(cid:10)(cid:58)(cid:94)(cid:36)(cid:5)(cid:119)(cid:30)(cid:68)(cid:113)(cid:87)(cid:69)(cid:86)(cid:125)(cid:87)(cid:119)(cid:53)\\n\\n(cid:68)(cid:71)(cid:112)(cid:13)(cid:6)(cid:125)(cid:43)(cid:43)(cid:40)(cid:102)(cid:85)(cid:55)(cid:3)(cid:73)(cid:69)(cid:120)(cid:94)(cid:124)(cid:67)(cid:26)(cid:79)(cid:85)(cid:98)(cid:38)(cid:79)(cid:4)(cid:53)(cid:7)(cid:31)(cid:9)(cid:123)(cid:123)(cid:106)(cid:81)(cid:45)(cid:102)(cid:44)(cid:83)(cid:45)(cid:32)(cid:101)(cid:117)(cid:128)(cid:117)(cid:98)(cid:10)(cid:117)(cid:89)(cid:83)(cid:88)(cid:23)(cid:127)(cid:109)(cid:9)(cid:91)(cid:97)(cid:15)(cid:35)(cid:98)(cid:109)(cid:74)(cid:41)(cid:115)(cid:119)(cid:83)(cid:41)(cid:84)(cid:57)(cid:15)(cid:8)(cid:8)(cid:99)(cid:43)(cid:53)(cid:15)(cid:126)(cid:54)\\n\\n(cid:92)(cid:1)(cid:62)(cid:127)(cid:64)(cid:21)(cid:86)(cid:13)(cid:32)(cid:72)(cid:4)(cid:111)(cid:43)(cid:44)(cid:78)(cid:122)(cid:122)(cid:61)(cid:88)(cid:91)(cid:79)(cid:47)(cid:6)(cid:29)(cid:24)(cid:37)(cid:6)(cid:125)(cid:56)(cid:2)(cid:49)(cid:60)(cid:36)(cid:45)(cid:14)(cid:87)(cid:30)(cid:46)(cid:78)(cid:80)(cid:108)(cid:6)(cid:59)(cid:24)(cid:102)(cid:101)(cid:104)(cid:13)(cid:118)(cid:109)(cid:80)(cid:120)(cid:64)(cid:72)(cid:94)(cid:100)(cid:22)(cid:52)(cid:33)(cid:98)(cid:51)(cid:38)(cid:38)(cid:126)(cid:92)(cid:53)(cid:104)(cid:19)(cid:8)(cid:37)(cid:30)(cid:101)(cid:88)(cid:28)(cid:85)(cid:66)(cid:68)\\n\\nLa presente Factura Electrónica de Venta, es un título valor de acuerdo con lo establecido en el Código de Comercio y en especial en los artículos 621,772 y 774, el Decreto 2242 del 24 de noviembre de 2015 y el Decreto Único 1074 de mayo de 2015. El presente título valor se asimila en todos sus efectos a una letra de cambio Art.779 del Código de Comercio.\\n\\n(cid:115)(cid:2)(cid:90)(cid:56)(cid:119)(cid:40)(cid:43)(cid:38)(cid:102)(cid:118)(cid:112)(cid:76)(cid:116)(cid:47)(cid:65)(cid:35)(cid:62)(cid:15)(cid:29)(cid:79)(cid:121)(cid:104)(cid:88)(cid:83)(cid:126)(cid:37)(cid:60)(cid:54)(cid:100)(cid:20)(cid:27)(cid:51)(cid:99)(cid:31)(cid:18)(cid:48)(cid:47)(cid:82)(cid:18)(cid:5)(cid:68)(cid:94)(cid:101)(cid:85)(cid:8)(cid:60)(cid:127)(cid:50)(cid:48)(cid:41)(cid:108)(cid:58)(cid:63)(cid:41)(cid:30)(cid:84)(cid:88)(cid:9)(cid:78)(cid:24)(cid:111)(cid:9)(cid:54)(cid:59)(cid:47)(cid:33)(cid:39)(cid:32)(cid:105)(cid:61)(cid:56)(cid:58)(cid:120)(cid:12)(cid:89)(cid:30)(cid:87)\\n\\n(cid:65)(cid:62)(cid:125)(cid:117)(cid:74)(cid:65)(cid:86)(cid:97)(cid:60)(cid:62)(cid:12)(cid:75)(cid:28)(cid:71)(cid:8)(cid:80)(cid:15)(cid:62)(cid:21)(cid:53)(cid:13)(cid:78)(cid:29)(cid:57)(cid:46)(cid:121)(cid:21)(cid:5)(cid:85)(cid:48)(cid:54)(cid:108)(cid:48)(cid:121)(cid:62)(cid:29)(cid:85)(cid:95)(cid:54)(cid:42)(cid:23)(cid:36)(cid:107)(cid:100)(cid:64)(cid:91)(cid:67)(cid:61)(cid:16)(cid:97)(cid:15)(cid:86)(cid:73)(cid:18)(cid:118)(cid:31)(cid:90)(cid:73)(cid:74)(cid:13)(cid:49)(cid:86)(cid:107)(cid:94)(cid:13)(cid:86)(cid:51)(cid:15)(cid:7)(cid:72)(cid:8)(cid:40)(cid:51)(cid:51)(cid:116)(cid:32)(cid:7)\\n\\n(cid:113)(cid:11)(cid:35)(cid:67)(cid:111)(cid:89)(cid:43)(cid:41)(cid:2)(cid:44)(cid:106)(cid:76)(cid:60)(cid:103)(cid:71)(cid:108)(cid:109)(cid:12)(cid:107)(cid:45)(cid:66)(cid:71)(cid:104)(cid:98)(cid:4)(cid:99)(cid:39)(cid:19)(cid:68)(cid:100)(cid:16)(cid:35)(cid:118)(cid:106)(cid:66)(cid:40)(cid:44)(cid:118)(cid:8)(cid:96)(cid:70)(cid:28)(cid:88)(cid:123)(cid:13)(cid:43)(cid:16)(cid:71)(cid:83)(cid:3)(cid:24)(cid:112)(cid:50)(cid:1)(cid:17)(cid:89)(cid:110)(cid:39)(cid:17)(cid:29)(cid:17)(cid:125)(cid:35)(cid:112)(cid:63)(cid:35)(cid:32)(cid:60)(cid:40)(cid:63)(cid:95)(cid:103)(cid:92)(cid:108)(cid:108)(cid:40)(cid:57)\\n\\n(cid:128)(cid:66)(cid:94)(cid:94)(cid:94)(cid:66)(cid:128)(cid:1)(cid:2)(cid:14)(cid:36)(cid:10)(cid:126)(cid:33)(cid:44)(cid:80)(cid:127)(cid:22)(cid:11)(cid:93)(cid:33)(cid:103)(cid:123)(cid:103)(cid:115)(cid:28)(cid:81)(cid:31)(cid:128)(cid:69)(cid:22)(cid:67)(cid:57)(cid:101)(cid:85)(cid:71)(cid:98)(cid:101)(cid:72)(cid:121)(cid:121)(cid:59)(cid:7)(cid:74)(cid:49)(cid:66)(cid:120)(cid:22)(cid:86)(cid:25)(cid:118)(cid:76)(cid:57)(cid:69)(cid:46)(cid:51)(cid:47)(cid:48)(cid:39)(cid:115)(cid:8)(cid:82)(cid:39)(cid:60)(cid:89)(cid:70)(cid:76)(cid:82)(cid:121)(cid:32)(cid:88)(cid:23)(cid:120)(cid:100)(cid:3)(cid:101)(cid:3)\\n\\n1/1[/INST] Empresa: SODIMAC COLOMBIA S.A.\\nNit: 800.242.106-2\\nValor a pagar: 41.300,00\\nNumero de factura:hreta 40081hado243777\\nValor a pagar sin IVA: 34.705,89\\nIVA: 6.594,11\\nCUFE: 4c2a88ad96c5c3f1fbaf3bf03385d9aa2f2c791a2ffc432e6825d0b9e2a895560bd91e478e1abeb215dc9de2768cf764\\n\\nEmpresa: SODIMAC COLOMBIA S.A.\\nNit: 800.242.106-2\\nValor a pagar: 41.300,00\\nNumero de'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = response(messages(data[0].page_content))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"]\n",
    "    , attention_mask=inputs[\"attention_mask\"]\n",
    "    , max_new_tokens=200\n",
    "    ,do_sample=True\n",
    "    ,top_p=0.95\n",
    "    ,top_k=40\n",
    "    ,repetition_penalty=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta = \"\".join(tokenizer.batch_decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f8487a04-c751-45b4-ba4d-959fe99d13b1)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/urllib3/util/retry.py:474\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/urllib3/util/util.py:39\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/urllib3/connectionpool.py:538\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 538\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/urllib3/connectionpool.py:369\u001b[0m, in \u001b[0;36mHTTPConnectionPool._raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[0;32m--> 369\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsebuetnlp/mT5_multilingual_XLSum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# automatically figures out how to best use CPU + GPU for loading model\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# prevents running custom model files on your machine\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# which version of mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/transformers/modeling_utils.py:3582\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3563\u001b[0m         has_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3564\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m: revision,\n\u001b[1;32m   3565\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproxies\u001b[39m\u001b[38;5;124m\"\u001b[39m: proxies,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_files_only\u001b[39m\u001b[38;5;124m\"\u001b[39m: local_files_only,\n\u001b[1;32m   3569\u001b[0m         }\n\u001b[1;32m   3570\u001b[0m         cached_file_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3571\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_dir,\n\u001b[1;32m   3572\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_download\u001b[39m\u001b[38;5;124m\"\u001b[39m: force_download,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3580\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhas_file_kwargs,\n\u001b[1;32m   3581\u001b[0m         }\n\u001b[0;32m-> 3582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mhas_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_weights_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhas_file_kwargs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   3583\u001b[0m             Thread(\n\u001b[1;32m   3584\u001b[0m                 target\u001b[38;5;241m=\u001b[39mauto_conversion,\n\u001b[1;32m   3585\u001b[0m                 args\u001b[38;5;241m=\u001b[39m(pretrained_model_name_or_path,),\n\u001b[1;32m   3586\u001b[0m                 kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_errors_during_conversion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs},\n\u001b[1;32m   3587\u001b[0m                 name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThread-autoconversion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3588\u001b[0m             )\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m   3589\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3590\u001b[0m     \u001b[38;5;66;03m# Otherwise, no PyTorch file was found, maybe there is a TF or Flax model file.\u001b[39;00m\n\u001b[1;32m   3591\u001b[0m     \u001b[38;5;66;03m# We try those to give a helpful error message.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/transformers/utils/hub.py:655\u001b[0m, in \u001b[0;36mhas_file\u001b[0;34m(path_or_repo, filename, revision, proxies, token, local_files_only, cache_dir, repo_type, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;66;03m# Check if the file exists\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_hub_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_hf_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_user_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OfflineModeIsEnabled:\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m has_file_in_cache\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/requests/sessions.py:624\u001b[0m, in \u001b[0;36mSession.head\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a HEAD request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 624\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:66\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     68\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/requests/adapters.py:713\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[0;32m--> 713\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mReadTimeout\u001b[0m: (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f8487a04-c751-45b4-ba4d-959fe99d13b1)')"
     ]
    }
   ],
   "source": [
    "model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name,\n",
    "                                             device_map=\"auto\", # automatically figures out how to best use CPU + GPU for loading model\n",
    "                                             trust_remote_code=False, # prevents running custom model files on your machine\n",
    "                                             revision=\"main\") # which version of mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'BartForCausalLM' is not supported for summarization. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"
     ]
    }
   ],
   "source": [
    "response = pipeline(\"summarization\", model=model, max_new_tokens=500, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"Eres un asistente de facturas, solo hablas español, vas a recibir\n",
    "información de varias facturas y debes extraer la siguiente información y presentarla\n",
    "\n",
    "de esta forma y solo con estos datos:\n",
    "\n",
    "Empresa: Nombre de la empresa del documento\n",
    "Nit: Nit de la empresa del documento\n",
    "Valor a pagar: Valor a pagar mostrado en el documento\n",
    "Numero de factura: Numero de factura encontrado en el documento\n",
    "Valor a pagar: Valor a pagar\n",
    "Valor de IVA: Valor de iva\n",
    "CUFE: CUFE del documento\n",
    "\n",
    "A partir del siguiente documento:\n",
    "\n",
    "\"\"\"\n",
    "#messages = lambda x :[\n",
    "#    {\"role\": \"system\", \"content\": f\"{template}\"},\n",
    "#    {\"role\": \"user\", \"content\": f\"{x}\"},\n",
    "#]\n",
    "messages = lambda x: f\"{template} {x}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (1024). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    outputs = response(messages(data[0].page_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
