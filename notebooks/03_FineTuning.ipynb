{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with the fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 00:25:15.273726: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig, \n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer)\n",
    "\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os \n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data/\")\n",
    "pdf_files = [data_path / \"train/preprocess\" / f for f in os.listdir(data_path/ \"train/preprocess\") if f.endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = natsorted(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pdf_data = []\n",
    "for f in pdf_files:\n",
    "    try:\n",
    "        WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
    "        loader = PyPDFLoader(f)\n",
    "        data = loader.load()\n",
    "        pdf_data.append(WHITESPACE_HANDLER(filter_complex_metadata(data)[0].page_content))\n",
    "    except Exception as e:\n",
    "        pdf_data.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/train/Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data = []\n",
    "for index, row in df.iterrows():\n",
    "    true_data.append(f\"\"\"Empresa: {row[\"Empresa\"]}\n",
    "Nit: {row[\"Nit\"]}\n",
    "Factura: {row[\"Numero_Factura\"]}\n",
    "Base: {row[\"Base\"]}\n",
    "IVA: {row[\"IVA\"]}\n",
    "Total: {row[\"Total\"]}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "#from transformers import pipeline\n",
    "\n",
    "#question_answerer = pipeline(\"question-answering\", model=model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_func(example: str):\n",
    "    text = example[\"text\"]\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text, #We pass the text of the dataset\n",
    "        return_tensors=\"pt\", #The datatype that we want the output data\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=4065 #This is intrinsic to the len of the model\n",
    "    )\n",
    "    labels = tokenizer(example[\"output\"],\n",
    "        return_tensors=\"pt\", #The datatype that we want the output data\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=4065 #This is intrinsic to the len of the model\n",
    "    )\n",
    "                       \n",
    "    tokenized_inputs[\"labels\"]= labels[\"input_ids\"]\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'output'],\n",
       "        num_rows: 87\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'output'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dic = {\"text\": pdf_data, \"output\": true_data}\n",
    "dataset_dic = Dataset.from_dict(dataset_dic)\n",
    "dataset_dic = dataset_dic.train_test_split(0.1)\n",
    "dataset_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    #Se debe adicionar el token de pad\n",
    "    tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"}) \n",
    "    #También se debe actualizar en el modelo los nuevos largos del token\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081f8804ff21412da1e1730dfd3e1362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3ce56145bc48eeaa457d88a98c5c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_dataset = dataset_dic.map(tokenizer_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'output', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 87\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'output', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "                        task_type=\"SEQ_2_SEQ_LM\", # FLAN-T5\n",
    "                        r=32,\n",
    "                        lora_alpha=32,\n",
    "                        lora_dropout=0.05,\n",
    "                        target_modules = ['q',\"v\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load bitsandbytes native library: /home/kaiki/anaconda3/envs/tensorflow/lib/python3.11/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6: version `GLIBCXX_3.4.32' not found (required by /home/kaiki/anaconda3/envs/tensorflow/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_rocm61.so)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kaiki/anaconda3/envs/tensorflow/lib/python3.11/site-packages/bitsandbytes/cextension.py\", line 126, in <module>\n",
      "    lib = get_native_library()\n",
      "          ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kaiki/anaconda3/envs/tensorflow/lib/python3.11/site-packages/bitsandbytes/cextension.py\", line 104, in get_native_library\n",
      "    dll = ct.cdll.LoadLibrary(str(binary_path))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kaiki/anaconda3/envs/tensorflow/lib/python3.11/ctypes/__init__.py\", line 454, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kaiki/anaconda3/envs/tensorflow/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: /home/kaiki/anaconda3/envs/tensorflow/lib/python3.11/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6: version `GLIBCXX_3.4.32' not found (required by /home/kaiki/anaconda3/envs/tensorflow/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_rocm61.so)\n",
      "\n",
      "CUDA Setup failed despite CUDA being available. Please run the following command to get more information:\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n",
      "to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n",
      "and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g++ (GCC) 14.2.1 20240910\n",
      "Copyright (C) 2024 Free Software Foundation, Inc.\n",
      "Esto es software libre; vea el código para las condiciones de copia.  NO hay\n",
      "garantía; ni siquiera para MERCANTIBILIDAD o IDONEIDAD PARA UN PROPÓSITO EN\n",
      "PARTICULAR\n",
      "\n",
      "trainable params: 1,376,256 || all params: 78,337,408 || trainable%: 1.7568\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config).to(device)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 4\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= \"../models/\" + model_name + \"-lora-data-extraction\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    bf16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenizer_dataset[\"train\"],\n",
    "    eval_dataset=tokenizer_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc6dae6fe9b4cf6842ac03317cc1945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "You have to specify either decoder_input_ids or decoder_inputs_embeds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/transformers/trainer.py:3318\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3318\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3320\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3323\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3324\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/transformers/trainer.py:3363\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3362\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3363\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/accelerate/utils/operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/accelerate/utils/operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/torch/amp/autocast_mode.py:43\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/peft/peft_model.py:1785\u001b[0m, in \u001b[0;36mPeftModelForSeq2SeqLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, decoder_input_ids, decoder_attention_mask, decoder_inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1784\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1785\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1786\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1788\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1799\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder_attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1801\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:188\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1739\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1736\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1739\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/transformers/models/t5/modeling_t5.py:1007\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1006\u001b[0m     err_msg_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124minput_ids or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: You have to specify either decoder_input_ids or decoder_inputs_embeds"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 5211,\n",
       " 6392,\n",
       " 10,\n",
       " 3,\n",
       " 3651,\n",
       " 4327,\n",
       " 4906,\n",
       " 22772,\n",
       " 15,\n",
       " 6348,\n",
       " 2294,\n",
       " 115,\n",
       " 2469,\n",
       " 4060,\n",
       " 591,\n",
       " 26,\n",
       " 357,\n",
       " 15,\n",
       " 927,\n",
       " 115,\n",
       " 519,\n",
       " 4225,\n",
       " 115,\n",
       " 3647,\n",
       " 3647,\n",
       " 15,\n",
       " 2773,\n",
       " 89,\n",
       " 75,\n",
       " 89,\n",
       " 519,\n",
       " 3341,\n",
       " 15,\n",
       " 75,\n",
       " 2294,\n",
       " 4198,\n",
       " 15,\n",
       " 357,\n",
       " 15,\n",
       " 4448,\n",
       " 3264,\n",
       " 115,\n",
       " 89,\n",
       " 1298,\n",
       " 9,\n",
       " 89,\n",
       " 536,\n",
       " 15442,\n",
       " 9,\n",
       " 5865,\n",
       " 26,\n",
       " 9,\n",
       " 15,\n",
       " 3539,\n",
       " 4122,\n",
       " 9,\n",
       " 9,\n",
       " 75,\n",
       " 4608,\n",
       " 89,\n",
       " 591,\n",
       " 3951,\n",
       " 3628,\n",
       " 26,\n",
       " 2128,\n",
       " 2128,\n",
       " 3710,\n",
       " 519,\n",
       " 26,\n",
       " 3710,\n",
       " 377,\n",
       " 16375,\n",
       " 3597,\n",
       " 11151,\n",
       " 283,\n",
       " 5905,\n",
       " 10781,\n",
       " 667,\n",
       " 180,\n",
       " 5,\n",
       " 188,\n",
       " 5,\n",
       " 134,\n",
       " 5,\n",
       " 445,\n",
       " 3177,\n",
       " 5,\n",
       " 3,\n",
       " 3914,\n",
       " 23758,\n",
       " 4853,\n",
       " 5,\n",
       " 4440,\n",
       " 20445,\n",
       " 71,\n",
       " 1744,\n",
       " 9,\n",
       " 2138,\n",
       " 138,\n",
       " 9,\n",
       " 10,\n",
       " 480,\n",
       " 448,\n",
       " 943,\n",
       " 205,\n",
       " 335,\n",
       " 180,\n",
       " 5905,\n",
       " 898,\n",
       " 536,\n",
       " 3,\n",
       " 18,\n",
       " 10285,\n",
       " 5,\n",
       " 1844,\n",
       " 3,\n",
       " 632,\n",
       " 2560,\n",
       " 2773,\n",
       " 17402,\n",
       " 32,\n",
       " 10,\n",
       " 480,\n",
       " 448,\n",
       " 9065,\n",
       " 12210,\n",
       " 6897,\n",
       " 3,\n",
       " 18,\n",
       " 10285,\n",
       " 5,\n",
       " 1844,\n",
       " 3,\n",
       " 632,\n",
       " 2560,\n",
       " 1714,\n",
       " 10636,\n",
       " 154,\n",
       " 89,\n",
       " 106,\n",
       " 32,\n",
       " 3,\n",
       " 2,\n",
       " 2532,\n",
       " 32,\n",
       " 10,\n",
       " 41,\n",
       " 3436,\n",
       " 7256,\n",
       " 1640,\n",
       " 591,\n",
       " 1630,\n",
       " 3,\n",
       " 4508,\n",
       " 3,\n",
       " 18,\n",
       " 3147,\n",
       " 668,\n",
       " 24636,\n",
       " 23360,\n",
       " 8067,\n",
       " 3820,\n",
       " 2,\n",
       " 29,\n",
       " 3,\n",
       " 18,\n",
       " 18898,\n",
       " 1649,\n",
       " 7,\n",
       " 5041,\n",
       " 7,\n",
       " 179,\n",
       " 20,\n",
       " 27,\n",
       " 8230,\n",
       " 10750,\n",
       " 60,\n",
       " 17,\n",
       " 5,\n",
       " 3,\n",
       " 35,\n",
       " 9405,\n",
       " 9,\n",
       " 7127,\n",
       " 4200,\n",
       " 2534,\n",
       " 3916,\n",
       " 8037,\n",
       " 5,\n",
       " 460,\n",
       " 21912,\n",
       " 10750,\n",
       " 60,\n",
       " 17,\n",
       " 5,\n",
       " 86,\n",
       " 26,\n",
       " 5,\n",
       " 3,\n",
       " 63,\n",
       " 638,\n",
       " 26694,\n",
       " 32,\n",
       " 8067,\n",
       " 3820,\n",
       " 2,\n",
       " 29,\n",
       " 7127,\n",
       " 5,\n",
       " 3420,\n",
       " 2128,\n",
       " 357,\n",
       " 309,\n",
       " 447,\n",
       " 5,\n",
       " 850,\n",
       " 21912,\n",
       " 10750,\n",
       " 5584,\n",
       " 20013,\n",
       " 206,\n",
       " 935,\n",
       " 9,\n",
       " 12765,\n",
       " 20,\n",
       " 27188,\n",
       " 7,\n",
       " 9580,\n",
       " 20,\n",
       " 40,\n",
       " 209,\n",
       " 8761,\n",
       " 5864,\n",
       " 2313,\n",
       " 7127,\n",
       " 5,\n",
       " 309,\n",
       " 21758,\n",
       " 465,\n",
       " 3,\n",
       " 25828,\n",
       " 23714,\n",
       " 4165,\n",
       " 4240,\n",
       " 3539,\n",
       " 2122,\n",
       " 3,\n",
       " 89,\n",
       " 15,\n",
       " 3441,\n",
       " 460,\n",
       " 2773,\n",
       " 29511,\n",
       " 2517,\n",
       " 491,\n",
       " 460,\n",
       " 1828,\n",
       " 29511,\n",
       " 2517,\n",
       " 3,\n",
       " 13035,\n",
       " 15644,\n",
       " 9064,\n",
       " 29,\n",
       " 4922,\n",
       " 3113,\n",
       " 9,\n",
       " 9668,\n",
       " 2394,\n",
       " 371,\n",
       " 9262,\n",
       " 5905,\n",
       " 188,\n",
       " 3,\n",
       " 3577,\n",
       " 14196,\n",
       " 448,\n",
       " 2,\n",
       " 18830,\n",
       " 188,\n",
       " 3396,\n",
       " 3,\n",
       " 24992,\n",
       " 188,\n",
       " 465,\n",
       " 5,\n",
       " 9580,\n",
       " 18,\n",
       " 14388,\n",
       " 20889,\n",
       " 8472,\n",
       " 3221,\n",
       " 9857,\n",
       " 2973,\n",
       " 221,\n",
       " 23744,\n",
       " 2442,\n",
       " 5,\n",
       " 6296,\n",
       " 75,\n",
       " 159,\n",
       " 287,\n",
       " 459,\n",
       " 195,\n",
       " 32,\n",
       " 5,\n",
       " 287,\n",
       " 5,\n",
       " 509,\n",
       " 6371,\n",
       " 15,\n",
       " 10,\n",
       " 445,\n",
       " 3177,\n",
       " 5,\n",
       " 87,\n",
       " 254,\n",
       " 5,\n",
       " 254,\n",
       " 10,\n",
       " 7454,\n",
       " 15,\n",
       " 75,\n",
       " 12765,\n",
       " 10,\n",
       " 382,\n",
       " 15,\n",
       " 40,\n",
       " 154,\n",
       " 89,\n",
       " 106,\n",
       " 32,\n",
       " 10,\n",
       " 4385,\n",
       " 76,\n",
       " 14677,\n",
       " 10,\n",
       " 371,\n",
       " 15,\n",
       " 3441,\n",
       " 11543,\n",
       " 2414,\n",
       " 10,\n",
       " 784,\n",
       " 188,\n",
       " 87,\n",
       " 329,\n",
       " 87,\n",
       " 308,\n",
       " 908,\n",
       " 10,\n",
       " 4163,\n",
       " 3441,\n",
       " 7281,\n",
       " 75,\n",
       " 4133,\n",
       " 35,\n",
       " 235,\n",
       " 10,\n",
       " 784,\n",
       " 188,\n",
       " 87,\n",
       " 329,\n",
       " 87,\n",
       " 308,\n",
       " 908,\n",
       " 10,\n",
       " 7337,\n",
       " 17694,\n",
       " 10,\n",
       " 553,\n",
       " 14550,\n",
       " 127,\n",
       " 10,\n",
       " 1289,\n",
       " 9008,\n",
       " 19042,\n",
       " 1276,\n",
       " 12416,\n",
       " 32,\n",
       " 3,\n",
       " 87,\n",
       " 3,\n",
       " 5618,\n",
       " 10,\n",
       " 20291,\n",
       " 9853,\n",
       " 667,\n",
       " 301,\n",
       " 4652,\n",
       " 16613,\n",
       " 7212,\n",
       " 2990,\n",
       " 21758,\n",
       " 3,\n",
       " 4450,\n",
       " 4056,\n",
       " 4177,\n",
       " 4433,\n",
       " 3,\n",
       " 3449,\n",
       " 20987,\n",
       " 5176,\n",
       " 3,\n",
       " 21605,\n",
       " 3765,\n",
       " 997,\n",
       " 1713,\n",
       " 3,\n",
       " 4440,\n",
       " 188,\n",
       " 3,\n",
       " 18,\n",
       " 22012,\n",
       " 3,\n",
       " 21357,\n",
       " 12735,\n",
       " 3162,\n",
       " 19818,\n",
       " 26814,\n",
       " 927,\n",
       " 18,\n",
       " 4305,\n",
       " 460,\n",
       " 2266,\n",
       " 18,\n",
       " 4018,\n",
       " 18,\n",
       " 4305,\n",
       " 8472,\n",
       " 3221,\n",
       " 27415,\n",
       " 10491,\n",
       " 667,\n",
       " 8761,\n",
       " 956,\n",
       " 6048,\n",
       " 446,\n",
       " 1265,\n",
       " 5033,\n",
       " 4935,\n",
       " 279,\n",
       " 5017,\n",
       " 4935,\n",
       " 6302,\n",
       " 332,\n",
       " 3063,\n",
       " 377,\n",
       " 9262,\n",
       " 5905,\n",
       " 3291,\n",
       " 13209,\n",
       " 3,\n",
       " 20006,\n",
       " 188,\n",
       " 5531,\n",
       " 249,\n",
       " 25710,\n",
       " 975,\n",
       " 3,\n",
       " 17,\n",
       " 76,\n",
       " 1503,\n",
       " 4885,\n",
       " 3,\n",
       " 63,\n",
       " 3,\n",
       " 11057,\n",
       " 9,\n",
       " 3,\n",
       " 17,\n",
       " 76,\n",
       " 27188,\n",
       " 5,\n",
       " 279,\n",
       " 152,\n",
       " 8135,\n",
       " 14382,\n",
       " 9,\n",
       " 276,\n",
       " 2975,\n",
       " 19604,\n",
       " 209,\n",
       " 20,\n",
       " 209,\n",
       " 3,\n",
       " 18,\n",
       " 4083,\n",
       " 22120,\n",
       " 6431,\n",
       " 188,\n",
       " 3597,\n",
       " 2,\n",
       " 567,\n",
       " 3,\n",
       " 8727,\n",
       " 2,\n",
       " 371,\n",
       " 15038,\n",
       " 3396,\n",
       " 377,\n",
       " 9262,\n",
       " 5905,\n",
       " 188,\n",
       " 3,\n",
       " 3577,\n",
       " 14196,\n",
       " 448,\n",
       " 2,\n",
       " 18830,\n",
       " 188,\n",
       " 3,\n",
       " 18,\n",
       " 3174,\n",
       " 162,\n",
       " 15,\n",
       " 26,\n",
       " 127,\n",
       " 3,\n",
       " 24757,\n",
       " 29,\n",
       " 32,\n",
       " 40,\n",
       " 4922,\n",
       " 122,\n",
       " 5807,\n",
       " 10,\n",
       " 3,\n",
       " 14945,\n",
       " 6338,\n",
       " 180,\n",
       " 5,\n",
       " 188,\n",
       " 5,\n",
       " 134,\n",
       " 5,\n",
       " 2504,\n",
       " 17,\n",
       " 10,\n",
       " 3,\n",
       " 4959,\n",
       " 12734,\n",
       " 2688,\n",
       " 5,\n",
       " 24151,\n",
       " 4278,\n",
       " 505,\n",
       " 19277,\n",
       " 2688,\n",
       " 24151,\n",
       " 5525,\n",
       " 14919,\n",
       " 89,\n",
       " 15,\n",
       " 208,\n",
       " 102,\n",
       " 3,\n",
       " 2,\n",
       " 3524,\n",
       " 205,\n",
       " 4922,\n",
       " 5572,\n",
       " 32,\n",
       " 374,\n",
       " 17,\n",
       " 13701,\n",
       " 272,\n",
       " 7039,\n",
       " 1072,\n",
       " 17,\n",
       " 15644,\n",
       " 5645,\n",
       " 26,\n",
       " 5,\n",
       " 3833,\n",
       " 127,\n",
       " 5579,\n",
       " 5,\n",
       " 27,\n",
       " 8230,\n",
       " 3325,\n",
       " 9273,\n",
       " 6654,\n",
       " 4200,\n",
       " 3,\n",
       " 13110,\n",
       " 1914,\n",
       " 632,\n",
       " 4225,\n",
       " 4200,\n",
       " 957,\n",
       " 4200,\n",
       " 8798,\n",
       " 6,\n",
       " 1458,\n",
       " 948,\n",
       " 4200,\n",
       " 5055,\n",
       " 755,\n",
       " 2596,\n",
       " 209,\n",
       " 3,\n",
       " 10077,\n",
       " 4542,\n",
       " 180,\n",
       " 5618,\n",
       " 27481,\n",
       " 3,\n",
       " 21342,\n",
       " 329,\n",
       " 8742,\n",
       " 5091,\n",
       " 3,\n",
       " 26342,\n",
       " 188,\n",
       " 3,\n",
       " 476,\n",
       " 205,\n",
       " 6727,\n",
       " 25683,\n",
       " 332,\n",
       " 25470,\n",
       " 262,\n",
       " 4490,\n",
       " 3390,\n",
       " 21796,\n",
       " 23,\n",
       " 26,\n",
       " 127,\n",
       " 10750,\n",
       " 5584,\n",
       " 26,\n",
       " 32,\n",
       " 3967,\n",
       " 5379,\n",
       " 7923,\n",
       " 22908,\n",
       " 122,\n",
       " 9,\n",
       " 1649,\n",
       " 75,\n",
       " 23,\n",
       " 346,\n",
       " 14533,\n",
       " 3,\n",
       " 63,\n",
       " 16922,\n",
       " 32,\n",
       " 445,\n",
       " 15729,\n",
       " 3,\n",
       " 63,\n",
       " 205,\n",
       " 5,\n",
       " 254,\n",
       " 5,\n",
       " 25252,\n",
       " 235,\n",
       " 1947,\n",
       " 27,\n",
       " 8230,\n",
       " 1318,\n",
       " 10496,\n",
       " 5,\n",
       " 279,\n",
       " 32,\n",
       " 40,\n",
       " 7,\n",
       " 9,\n",
       " 9273,\n",
       " 3,\n",
       " 9,\n",
       " 2576,\n",
       " 1478,\n",
       " 4163,\n",
       " 3441,\n",
       " 3,\n",
       " 63,\n",
       " 3,\n",
       " 21783,\n",
       " 20,\n",
       " 17993,\n",
       " 12765,\n",
       " 10,\n",
       " 9273,\n",
       " 3,\n",
       " 40,\n",
       " 2,\n",
       " 29,\n",
       " 15,\n",
       " 9,\n",
       " 7,\n",
       " 10,\n",
       " 209,\n",
       " 20123,\n",
       " 23,\n",
       " 32,\n",
       " 20,\n",
       " 2709,\n",
       " 839,\n",
       " 10,\n",
       " 5693,\n",
       " 5985,\n",
       " 71,\n",
       " 30416,\n",
       " 188,\n",
       " 11466,\n",
       " 2,\n",
       " 329,\n",
       " 14871,\n",
       " 3396,\n",
       " 3396,\n",
       " 8040,\n",
       " 9138,\n",
       " 3597,\n",
       " 2,\n",
       " 567,\n",
       " 3,\n",
       " 18284,\n",
       " 10744,\n",
       " 6759,\n",
       " 134,\n",
       " 3396,\n",
       " 411,\n",
       " 25683,\n",
       " 3,\n",
       " 28007,\n",
       " 309,\n",
       " 2,\n",
       " 3291,\n",
       " 16018,\n",
       " 9,\n",
       " 27642,\n",
       " 10,\n",
       " 695,\n",
       " 1216,\n",
       " 5900,\n",
       " 51,\n",
       " 4741,\n",
       " 32,\n",
       " 20,\n",
       " 50,\n",
       " 312,\n",
       " 63,\n",
       " 586,\n",
       " 3341,\n",
       " 20,\n",
       " 2628,\n",
       " 6,\n",
       " 1794,\n",
       " 3286,\n",
       " 9,\n",
       " 26,\n",
       " 9,\n",
       " 5569,\n",
       " 50,\n",
       " 312,\n",
       " 63,\n",
       " 898,\n",
       " 3959,\n",
       " 20,\n",
       " 2038,\n",
       " 50,\n",
       " 3967,\n",
       " 7197,\n",
       " 9,\n",
       " 649,\n",
       " 2975,\n",
       " 5569,\n",
       " 3,\n",
       " 9,\n",
       " 6873,\n",
       " 9,\n",
       " 26,\n",
       " 9,\n",
       " 19598,\n",
       " 6117,\n",
       " 179,\n",
       " 297,\n",
       " 15,\n",
       " 50,\n",
       " 27188,\n",
       " 3,\n",
       " 9,\n",
       " 10381,\n",
       " 3,\n",
       " 929,\n",
       " 7,\n",
       " 10153,\n",
       " 3,\n",
       " 26,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 107,\n",
       " 2975,\n",
       " 3727,\n",
       " 15,\n",
       " 7,\n",
       " 108,\n",
       " 7938,\n",
       " 4617,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 2629,\n",
       " 9088,\n",
       " 102,\n",
       " 12765,\n",
       " 6,\n",
       " 20,\n",
       " 6899,\n",
       " 5314,\n",
       " 52,\n",
       " 23,\n",
       " 32,\n",
       " 6,\n",
       " 3,\n",
       " 15,\n",
       " 40,\n",
       " 5026,\n",
       " 10557,\n",
       " 32,\n",
       " 142,\n",
       " 3261,\n",
       " 291,\n",
       " 2975,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 1313,\n",
       " 8825,\n",
       " 7,\n",
       " 20,\n",
       " 40,\n",
       " 26680,\n",
       " 32,\n",
       " 11924,\n",
       " 52,\n",
       " 15742,\n",
       " 5807,\n",
       " 3,\n",
       " 9,\n",
       " 10401,\n",
       " 23,\n",
       " 9,\n",
       " 26,\n",
       " 32,\n",
       " 5,\n",
       " 1289,\n",
       " 2576,\n",
       " 839,\n",
       " 20,\n",
       " 50,\n",
       " 27188,\n",
       " 142,\n",
       " 16200,\n",
       " 52,\n",
       " 2975,\n",
       " 491,\n",
       " 3,\n",
       " 17,\n",
       " 4632,\n",
       " 127,\n",
       " 4553,\n",
       " 2,\n",
       " 2998,\n",
       " 32,\n",
       " 20,\n",
       " 3,\n",
       " 154,\n",
       " 2427,\n",
       " 6,\n",
       " 3,\n",
       " 35,\n",
       " 50,\n",
       " 3,\n",
       " 89,\n",
       " 15,\n",
       " 3441,\n",
       " 20,\n",
       " 40,\n",
       " 3,\n",
       " 1926,\n",
       " 75,\n",
       " 4133,\n",
       " 35,\n",
       " 235,\n",
       " 5569,\n",
       " 3,\n",
       " 15,\n",
       " 40,\n",
       " 409,\n",
       " 322,\n",
       " 3134,\n",
       " 32,\n",
       " 238,\n",
       " 741,\n",
       " 15,\n",
       " 93,\n",
       " 4987,\n",
       " 899,\n",
       " 20,\n",
       " 10381,\n",
       " 93,\n",
       " 1071,\n",
       " 35,\n",
       " 235,\n",
       " 7,\n",
       " 5569,\n",
       " 3,\n",
       " 1306,\n",
       " 3,\n",
       " 63,\n",
       " 20032,\n",
       " 15,\n",
       " 7,\n",
       " 5,\n",
       " 3144,\n",
       " 3,\n",
       " 2165,\n",
       " 14846,\n",
       " 1745,\n",
       " 9,\n",
       " 10305,\n",
       " 20,\n",
       " 259,\n",
       " 9,\n",
       " 27188,\n",
       " 520,\n",
       " 554,\n",
       " 19029,\n",
       " 3134,\n",
       " 32,\n",
       " 7,\n",
       " 975,\n",
       " 93,\n",
       " 1071,\n",
       " 35,\n",
       " 235,\n",
       " 7,\n",
       " 12507,\n",
       " 28594,\n",
       " 5,\n",
       " 4853,\n",
       " 6,\n",
       " 1458,\n",
       " 948,\n",
       " 4200,\n",
       " 3,\n",
       " 10667,\n",
       " 940,\n",
       " 6,\n",
       " 4608,\n",
       " 20677,\n",
       " 591,\n",
       " 9526,\n",
       " 6,\n",
       " 27308,\n",
       " 5,\n",
       " 2534,\n",
       " 460,\n",
       " 2266,\n",
       " 18,\n",
       " 4018,\n",
       " 18,\n",
       " 4305,\n",
       " 12046,\n",
       " 10,\n",
       " 3288,\n",
       " 10,\n",
       " 3420,\n",
       " 427,\n",
       " 89,\n",
       " 25848,\n",
       " 32,\n",
       " 17402,\n",
       " 32,\n",
       " 3274,\n",
       " 9526,\n",
       " 27308,\n",
       " 4200,\n",
       " 1174,\n",
       " 51,\n",
       " 448,\n",
       " 32,\n",
       " 17,\n",
       " 6864,\n",
       " 8011,\n",
       " 10,\n",
       " 11543,\n",
       " 2414,\n",
       " 6392,\n",
       " 11527,\n",
       " 1808,\n",
       " 3,\n",
       " 87,\n",
       " 3,\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_dataset[\"train\"][\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
